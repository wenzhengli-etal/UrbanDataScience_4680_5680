{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240d0247-f215-48f3-8dd2-befff5838912",
   "metadata": {},
   "source": [
    "## Week2_9_DataCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977bafd-a38d-4f7a-9b74-166d3563e135",
   "metadata": {},
   "source": [
    "Outline\n",
    "1. Introduction to Selenium\n",
    "2. Control Web Browser Using Selenium\n",
    "3. Web Scraping in a Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8f384-5d44-41a2-b914-22f6dd610f03",
   "metadata": {},
   "source": [
    "## 1. Introduction to Selenium\n",
    "\n",
    "Selenium is a Python module (library/package) for web automation and testing. It allows you to control a web browser through your scripts, enabling you to automate tasks such as filling out forms, clicking buttons, navigating pages, and extracting data. Selenium is commonly used for web scraping, automated testing of web applications, and performing repetitive web-based tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19b660-a8fb-45e8-9b27-1aa4636b0ce1",
   "metadata": {},
   "source": [
    "### 1.1 Install selenium\n",
    "We are using selenium to obtain data from webpages. Now, launch the Jupyter Notebook and\n",
    "import selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb874642-cbb8-4f72-ad82-f8f3db0c24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35649a-4319-4294-8b90-1b4eb6c06cbd",
   "metadata": {},
   "source": [
    "![p1](img/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cb60f-3944-4e0e-b6f6-dbbb4ef2933e",
   "metadata": {},
   "source": [
    "This error indicates that the selenium is not installed in your computer. To install a package into its own environment, please follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06499bdb-b45e-4bde-87d4-a6e193636884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lwz12\\anaconda3\\envs\\gds_py\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lwz12\\anaconda3\\envs\\gds_py\\lib\\site-packages (from selenium) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "# the first way: \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd0306-0aba-4326-a512-716693eca3dc",
   "metadata": {},
   "source": [
    "An alternative way:\n",
    "- (1) Open Anaconda Navigator.\n",
    "- (2) Click Connect, then click SIGN IN next to Anaconda.org.\n",
    "- (3) Select Environments from the left-hand navigation, then look for your package by name using the Search Packages field (**make sure you select \"All\" module, not merely those \"Installed\"**). Filter packages further using the dropdown above the Name column.\n",
    "- (4) Select the checkbox of the selenium you want to install, then click the Apply.\n",
    "\n",
    "![p1](img/p2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ab0d4-023e-4cd4-9392-fa58a30658a6",
   "metadata": {},
   "source": [
    "Now `import selenium` again. There should be no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b02c3ba-ddfe-4b37-a5ed-218ac78741a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf498a-0117-49ea-a2b0-4f3cbffcf253",
   "metadata": {},
   "source": [
    "Then we create a brower representing the web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a0f36-7ef5-4988-8a2f-d3c450056d86",
   "metadata": {},
   "source": [
    "### 1.2 Download webdriver\n",
    "Using *selenium* to control web browser requires a webdriver application, which is available from the selenium\n",
    "website.\n",
    "1. Go to the website (https://selenium.dev/) and click \"Download\";\n",
    "2. Scroll down and you can see \"Platforms Supported by Selenium\". Under \"Browser\", there is a list of web\n",
    "browsers. Click your daily choice and download it accordingly.\n",
    "3. Unzip the downloaded file and save the application file in the Notebook folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aaf914-0bc2-4017-917c-1599f02379da",
   "metadata": {},
   "source": [
    "## 2. Control Web Browser Using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a68a9-ef14-46f8-8c6c-f76203a32de4",
   "metadata": {},
   "source": [
    "### 2.1 Import selenium and launch web brower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5903b-01a1-42a0-8baf-72198e72a82a",
   "metadata": {},
   "source": [
    "First, we import selenium in the following way. In this way, we import the module webdriver from the big library selenium so that we can call webdriver directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e969812-e291-48b2-9752-d2027cba627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19514c9-23c6-4e6a-9aeb-87a059154299",
   "metadata": {},
   "source": [
    "Then we create a brower representing the web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab924b2d-e901-46e7-9468-3e5e4ac6a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask the webdriver to open a google chrome page for us\n",
    "browser = webdriver.Chrome('chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cd9ac-fc86-4d2e-9a52-e8862c82c81c",
   "metadata": {},
   "source": [
    "You may see some safety warning message from your system, just allow it. Now, you should see a new web browser launched.\n",
    "\n",
    "For a different web browser, you need to change the function name (after the webdriver. ) as well as the driver application name. For example,\n",
    "- browser = webdriver.Chrome('chromedriver')\n",
    "- browser = webdriver.Firefox('geckodriver')\n",
    "- browser = webdriver.Edge('msedgedriver')\n",
    "\n",
    "Now, we can surf the internet using selenium and this browser ! Let's try Google first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77d8fda3-1fea-4a68-9fdb-ed35bec7cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter URL of google:\n",
    "browser.get('http://www.google.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105f322-a0d3-4444-9ba3-8714bb2c0e37",
   "metadata": {},
   "source": [
    "**Notice** that for some browers, you must keep \"http://\" in the web address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed462dda-ef91-4db2-b88a-0350fee05b03",
   "metadata": {},
   "source": [
    "### 2.2 Find Elements and Send Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81520bd5-7c35-4d9a-96b4-afb8182fa9d7",
   "metadata": {},
   "source": [
    "Let's search something. \n",
    "\n",
    "First, you need to find the search input window element by right clicking the search window and choose \"Inspect\". \n",
    "\n",
    "Find in the source codes the specific **\"id\" or \"name\"** of the input window and then use it in the function `find_element_by_id()` or `find_element_by_name()`. Here we find the name is \"q\", so we use this name and define an object (variable) search for the input window.\n",
    "\n",
    "![p1](img/p3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67123464-5a60-41da-aaa8-d66e36339853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the \"id\" or \"name\" of the input window\n",
    "search = browser.find_element_by_name('q')\n",
    "\n",
    "# An alternative way:\n",
    "# search = browser.find_element_by_id(\"APjFqb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159dfaa-9597-44a2-ab7e-c4a4bee790d5",
   "metadata": {},
   "source": [
    "To type in texts in the window, you can call the search and use the function `send_keys()`. For example, we\n",
    "search \"selenium\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bbd0a6f-81f6-46d1-a43d-7c4056be2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type something in the search bar using .send_keys\n",
    "search.send_keys('selenium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497af22-c10b-44fd-b485-84dc31aed394",
   "metadata": {},
   "source": [
    "Next, we want to run the search through pressing ENTER. Selenium can do that through the function `search.send_keys(Keys.ENTER)`. But before running it, you need to import Keys from the big library Selenium.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cdd0096-18ab-4881-bec4-18038c779ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Keys from selenium. \n",
    "# the Keys class simulates keyboard key presses in a web browser\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# press ENTER\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0c71f-ffa4-4d75-b01a-2f4b804fab92",
   "metadata": {},
   "source": [
    "Congratulations! You just controlled the web browser to search selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed0c71-8607-402b-b243-1d4abfb11e0b",
   "metadata": {},
   "source": [
    "Let's try a different website, our class roster website https://classes.cornell.edu/browse/roster/SP23). We want to search for available econometric courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d9e45e-5228-407c-a362-da8f5123c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the website: \n",
    "browser.get('https://classes.cornell.edu/browse/roster/SP23')\n",
    "\n",
    "# find the element by id\n",
    "search = browser.find_element_by_id('q') # how could you find the name \"q\"?\n",
    "\n",
    "# type \"econometrics\" in the search bar\n",
    "search.send_keys('econometrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab94c93-a040-4e76-a275-a2bee48f369f",
   "metadata": {},
   "source": [
    "Another way to run the search\n",
    "- we can click the \"Go\" button. First, we need to find the button name (\"search-go\"), and assign it to a variable search_button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "980fff75-4b72-4ec8-b5b3-b3db9bf239e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the \"Go\" button\n",
    "search_button = browser.find_element_by_id('search-go')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c28b80-8c69-4d32-80aa-af5929c208b2",
   "metadata": {},
   "source": [
    "To click it, you call this search_button and use the function click() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13fd28b2-0f5f-4b94-9dbc-b82f8956bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the go button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96a951-8e2b-4ae1-bfb1-a626549d3bc4",
   "metadata": {},
   "source": [
    "### 2.3 Find Text using xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a627d7-8053-4caf-9b48-eff85f622617",
   "metadata": {},
   "source": [
    "Now, if we want to save the information of all search results, how to do that? \n",
    "\n",
    "First of all, how can you identify the course title \"Econometrics I\" in the first result? If you right click the title and check the source code, you may find no id or name available for the text. An alternative way is to use `find_element_by_xpath()`, a function that navigates to the target text based on Xpath. \n",
    "\n",
    "**XPath** is the language used for locating nodes in an XML document (also works for HTML). To get the xpath, we right click the source code you want to locate, and go to \"Copy\" and then \"Copy XPath\". Then paste it into the function `find_element_by_xpath()`.\n",
    "\n",
    "Note that there are many functions for locating element(s), for more of the family `find_element(s)_by_`, find this click: https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "![p1](img/p4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2621b54-1625-4843-be15-dd155bc85cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the XPath method: .find_element_by_xpath: \n",
    "title = browser.find_element_by_xpath('//*[@id=\"dtitle-AEM7100\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676171a-ad7c-48f4-97a0-a25871a175bc",
   "metadata": {},
   "source": [
    "To get the text inside source code, we call the title and use the function .text() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b52a5b-64fe-4cdf-9c44-86a60cea0607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Econometrics I'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the text\n",
    "title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a12e5d-bf0a-4be8-876e-6d7802bd870d",
   "metadata": {},
   "source": [
    "## 3. Test yourself\n",
    "\n",
    "### 3.1 Can you do the following steps using Selenium in Python?\n",
    "1. Launch your web browser and open the class roster website https://classes.cornell.edu/browse/roster/SP23;\n",
    "2. Search \"Econometrics\";\n",
    "3. Obtain and print (in Python) the class number, class title, class weekdays, class time, and class instructor for the first course.\n",
    "Hint: you can use `.get_attribute('any attribute name')` to get any attribute value of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f25648b5-91d0-4428-8b8b-466df7c208d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Launch your web browser and open the class roster website https://classes.cornell.edu/browse/roster/SP23;\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "# launch the web browser\n",
    "browser = webdriver.Chrome('chromedriver')\n",
    "\n",
    "# open the website\n",
    "browser.get('https://classes.cornell.edu/browse/roster/SP23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a862b6e8-8337-4221-bb2e-0b3d367e55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Search \"Econometrics\";\n",
    "\n",
    "# find the search bar\n",
    "search = browser.find_element_by_id('q')\n",
    "\n",
    "# type in 'econometrics'\n",
    "search.send_keys('econometrics')\n",
    "\n",
    "# find the GO button\n",
    "search_button = browser.find_element_by_id('search-go')\n",
    "\n",
    "# click the button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "279e6a68-53b3-4094-95da-fa22cdc5420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEM 7100\n",
      "Econometrics I\n",
      "W\n",
      "2:40pm - 5:10pm\n",
      "Shanjun Li (sl2448)\n"
     ]
    }
   ],
   "source": [
    "# (3) Obtain and print (in Python) the class number, class title, class weekdays, class time, and class instructor.\n",
    "\n",
    "# class number\n",
    "c_number = browser.find_element_by_xpath('//*[@id=\"head-AEM-7100\"]/div[1]')\n",
    "print(c_number.text)\n",
    "\n",
    "# class title\n",
    "c_title = browser.find_element_by_xpath('//*[@id=\"dtitle-AEM7100\"]') \n",
    "print(c_title.text)\n",
    "\n",
    "# class weekday\n",
    "c_weekday = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[3]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/span/span')\n",
    "print(c_weekday.text)\n",
    "\n",
    "# class time\n",
    "c_time = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[3]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/time')\n",
    "print(c_time.text)\n",
    "\n",
    "# class instructor\n",
    "c_instructor = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[3]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[3]/p/span')\n",
    "print(c_instructor.get_attribute('data-content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a997fca-ec75-40ec-9251-64c775f1da23",
   "metadata": {},
   "source": [
    "### 3.2 Try getting the same information for the second result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc6e1781-4ed9-4c1b-8ab8-115b55e51dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEE 6640\n",
      "Microeconometrics of Discrete Choice\n",
      "TR\n",
      "11:25am - 12:40pm\n",
      "Ricardo Daziano (ra477)\n"
     ]
    }
   ],
   "source": [
    "# class number\n",
    "c_number = browser.find_element_by_xpath('//*[@id=\"head-CEE-6640\"]/div[1]')\n",
    "print(c_number.text)\n",
    "\n",
    "# class title\n",
    "c_title = browser.find_element_by_xpath('//*[@id=\"dtitle-CEE6640\"]')\n",
    "print(c_title.text)\n",
    "\n",
    "# class weekday\n",
    "c_weekday = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[4]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/span/span')\n",
    "print(c_weekday.text)\n",
    "\n",
    "# class time\n",
    "c_time = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[4]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/time')\n",
    "print(c_time.text)\n",
    "\n",
    "# class instructor\n",
    "c_instructor = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[4]/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[3]/p/span')\n",
    "print(c_instructor.get_attribute('data-content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ef1a6-67f4-482f-8f43-f7775325d867",
   "metadata": {},
   "source": [
    "## 4. Web Scraping in a Loop\n",
    "### 4.1 Question: Can we loop over all the results in the list?\n",
    "The current way to obtain each piece of information does not allow us to loop (why?). \n",
    "\n",
    "The key issue is that the XPathes of the class number and the class title contain course-specific information (e.g., \"head-CEE-6640\"), which are not loopable. In contrary, the XPathes of the class weekday, time, and instructor are loopable, because they are in the format of `relative position`. Thus, we need to find relative pathes to the class number and the class title elements.\n",
    "\n",
    "After analyzing the structure of the source code of the webpage (see lecture slides for details), we find the pathes for both elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62159d52-d5ba-4f5f-a6b0-f87b9476c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEM 7100\n",
      "Econometrics I\n"
     ]
    }
   ],
   "source": [
    "# AEM 7100\n",
    "# class number (using relative position XPath)\n",
    "c_number = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[3]/h3[1]/div[1]')\n",
    "print(c_number.text)\n",
    "\n",
    "# class title (using relative position XPath)\n",
    "c_title = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[3]/h3[1]/div[2]')\n",
    "print(c_title.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3562ba6c-cae7-4fde-8f43-04574514f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEE 6640\n",
      "Microeconometrics of Discrete Choice\n"
     ]
    }
   ],
   "source": [
    "# CEE 6640\n",
    "# class number (using relative position XPath)\n",
    "c_number = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[4]/h3[1]/div[1]')\n",
    "print(c_number.text)\n",
    "\n",
    "# class title (using relative position XPath)\n",
    "c_title = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[4]/h3[1]/div[2]')\n",
    "print(c_title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460e9be-e571-4f3b-8890-21c65c71cbb0",
   "metadata": {},
   "source": [
    "We also find that to loop from the first result to the second, we just need to change the index in the second div[] from 3 to 4. Thus, we can print the information of the first two results in a loop in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1e86f9d-b353-4366-aac3-a1f8a904a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEM 7100\n",
      "Econometrics I\n",
      "W\n",
      "2:40pm - 5:10pm\n",
      "Shanjun Li (sl2448)\n",
      "CEE 6640\n",
      "Microeconometrics of Discrete Choice\n",
      "TR\n",
      "11:25am - 12:40pm\n",
      "Ricardo Daziano (ra477)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):  #  note that i will take values of 0 and 1\n",
    "    \n",
    "    index = i + 3    # convert i into the index used for div[]\n",
    "    \n",
    "    # class number\n",
    "    c_number = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/h3[1]/div[1]')\n",
    "    print(c_number.text)\n",
    "\n",
    "    # class title\n",
    "    c_title = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/h3[1]/div[2]')\n",
    "    print(c_title.text)\n",
    "\n",
    "    # class weekday\n",
    "    c_weekday = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/span/span')\n",
    "    print(c_weekday.text)\n",
    "\n",
    "    # class time\n",
    "    c_time = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/time')\n",
    "    print(c_time.text)\n",
    "\n",
    "    # class instructor\n",
    "    c_instructor = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[3]/p/span')\n",
    "    print(c_instructor.get_attribute('data-content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aafe40-4a90-4537-8fb8-1fa513c5fce3",
   "metadata": {},
   "source": [
    "### 4.2. Loop and save the results\n",
    "Now, we want to loop and save all results into a DataFrame and then export it into an Excel file. To do this, we first need to save all the results in variable lists.\n",
    "\n",
    "\n",
    "#### 4.2.1 Save results into variable lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754e6aba-6da5-4db2-ac3f-3810f90a6dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEM 7100\n",
      "Econometrics I\n",
      "W\n",
      "2:40pm - 5:10pm\n",
      "Shanjun Li (sl2448)\n",
      "\n",
      "\n",
      "CEE 6640\n",
      "Microeconometrics of Discrete Choice\n",
      "TR\n",
      "11:25am - 12:40pm\n",
      "Ricardo Daziano (ra477)\n",
      "\n",
      "\n",
      "ECON 3120\n",
      "Applied Econometrics\n",
      "TR\n",
      "1:00pm - 2:15pm\n",
      "Douglas McKee (dmm399)\n",
      "\n",
      "\n",
      "ECON 3140\n",
      "Econometrics\n",
      "TR\n",
      "1:00pm - 2:15pm\n",
      "Joerg Stoye (js2434)\n",
      "\n",
      "\n",
      "ECON 6200\n",
      "Econometrics II\n",
      "TR\n",
      "9:40am - 10:55am\n",
      "Joerg Stoye (js2434)\n",
      "\n",
      "\n",
      "ECON 7230\n",
      "Semi and Non Parametric Econometrics\n",
      "R\n",
      "2:40pm - 5:10pm\n",
      "Francesca Molinari (fm72)\n",
      "\n",
      "\n",
      "ECON 7245\n",
      "Topics in Econometrics and Machine Learning\n",
      "T\n",
      "2:40pm - 5:10pm\n",
      "Jose Luis Montiel Olea (jlo67)\n",
      "\n",
      "\n",
      "ECON 7841\n",
      "Econometrics Workshop\n",
      "T\n",
      "11:15am - 12:45pm\n",
      "Joerg Stoye (js2434)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create empty lists for each variable to save results\n",
    "c_number_list = []\n",
    "c_title_list = []\n",
    "c_weekday_list = []\n",
    "c_time_list = []\n",
    "c_instructor_list = []\n",
    "\n",
    "for i in range(8):  #  note that i will take values from 0\n",
    "    \n",
    "    index = i + 3    # convert i into the index used for div[]\n",
    "    \n",
    "    # class number\n",
    "    c_number = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/h3[1]/div[1]')\n",
    "    print(c_number.text)\n",
    "    c_number_list.append(c_number.text)   # use .append() function to add the result to the list \n",
    "    \n",
    "    # class title\n",
    "    c_title = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/h3[1]/div[2]')\n",
    "    print(c_title.text)\n",
    "    c_title_list.append(c_title.text)\n",
    "\n",
    "    # class weekday\n",
    "    c_weekday = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/span/span')\n",
    "    print(c_weekday.text)\n",
    "    c_weekday_list.append(c_weekday.text)\n",
    "\n",
    "    # class time\n",
    "    c_time = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[1]/span/time')\n",
    "    print(c_time.text)\n",
    "    c_time_list.append(c_time.text)\n",
    "\n",
    "    # class instructor\n",
    "    c_instructor = browser.find_element_by_xpath('//*[@id=\"search-refresh\"]/div[2]/div[' + str(index) + ']/div[2]/div[1]/div[2]/ul[2]/li[4]/ul/li[3]/p/span')\n",
    "    print(c_instructor.get_attribute('data-content'))\n",
    "    c_instructor_list.append(c_instructor.get_attribute('data-content'))\n",
    "    \n",
    "    # print a blank line between two classes' results\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7202a7-2035-4480-98a3-ec9eb20d025f",
   "metadata": {},
   "source": [
    "#### 4.2.2 Combine the multiple lists into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1240d7b4-ad34-4a31-a97b-eabf011eac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bad8e52-9104-4a18-9320-db5e9b7d21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all lists into a Dataframe\n",
    "allresult = pd.DataFrame(\n",
    "    {'number': c_number_list,\n",
    "     'title': c_title_list,\n",
    "     'weekday': c_weekday_list,\n",
    "     'time': c_time_list,\n",
    "     'instructor':c_instructor_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5355bd8-eb84-42be-a416-4a01d04db22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result DataFrame to an Excel file\n",
    "allresult.to_excel('allresult.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d32bd-3eee-4345-aad2-97bab878a250",
   "metadata": {},
   "source": [
    "## 5. In-class Exercise (assignment 4 -  Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86077982-0750-403b-ac20-27cd5d795138",
   "metadata": {},
   "source": [
    "**Part 1 (30 Points)**\n",
    "\n",
    "Option 1:  Pick one course you are taking this semester and use Selenium to obtain the course information from the Class Roster (https://classes.cornell.edu/browse/roster/SP23). Your code should show the full process (15 Points) from launching the browser to printing all the information. The course information includes\n",
    "- a. ( 3 Points) Course number (e.g., CRP5850)\n",
    "- b. ( 3 Points) Course title\n",
    "- c. ( 3 Points) Course credits\n",
    "- d. ( 3 Points) Course instructor\n",
    "- e. ( 3 Points) Course time (weekday and time)\n",
    "\n",
    "Option 2: If your final project needs to collect data from a website, this is the chance you can develop a web-scraping algorithm to collect your own data and show in this assignment.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10991ab2-9bbf-4293-8700-4814d456378e",
   "metadata": {},
   "source": [
    "(Optional 10 pts) North Amiercan Food System Network (NAFSN) is a professional association of people working to strengthen local & regional food systems. They chronicle jobs that pay a living wage in food systems development. They glean employment opportunities daily from LinkedIn, other social media platforms, regional nonprofit networks, and post positions emailed to them directly. The job list is available at:  https://members.foodsystemsnetwork.org/members/classifieds5.php?org_id=NAFS\n",
    "\n",
    "By 6/12/2014, there are 538 jobs posted on the NAFSN website ï¼ˆnotice that your number may different from mine). Design a web-scraping algorithm to automatically collect all posted jobs, and save the data into a DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
